{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"seq2seq.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMMVxZJaOiuDv1pct2MrbJg"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"QxWM7suaiiRW"},"source":["import sys\n","sys.path.append('..')\n","from common.time_layers import *\n","from common.base_model import BaseModel"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4QKSMfq2cY35"},"source":["class Encoder:\n","    def __init__(self,vocab_size,wordvec_size,hidden_size):\n","        #重みの初期化\n","        V,D,H=vocab_size,wordvec_size,hidden_size\n","        rn=np.random.randn\n","\n","        embed_W=(rn(V,D)/100).astype('f')\n","        lstm_Wx=(rn(D,4*H)/np.sqrt(D)).astype('f')\n","        lstm_Wh=(rn(H,4*H)/np.sqrt(H)).astype('f')\n","        lstm_b=np.zeros(4*H).astype('f')\n","\n","        #レイヤの生成\n","        self.embed=TimeEmbedding(embed_W)\n","        self.lstm=TimeLSTM(lstm_Wx,lstm_Wh,lstm_b,stateful=False)   #短い時系列データが複数ある問題のため、隠れ状態は維持しない\n","\n","        #パラメータの格納\n","        self.params,self.grads=[],[]\n","        self.params=self.embed.params+self.lstm.params\n","        self.grads=self.embed.grads+self.lstm.grads\n","        self.hs=None\n","\n","    def forward(self,xs):\n","        xs=self.embed.forward(xs)\n","        hs=self.lstm.forward(xs)\n","        self.hs=hs\n","        return hs[:,-1,:]   #最後の時刻の隠れ状態のみデコーダに伝える\n","\n","    def backward(self,dh):\n","        dhs=np.zeros_like(self.hs)\n","        dhs[:,-1,:]=dh  #デコーダからの逆伝搬を最後の時刻の隠れ状態の勾配とする\n","        dout=self.lstm.backward(dhs)\n","        dout=self.embed.backward(dout)\n","        return dout"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AQHbMXq-s4eN"},"source":["class Decoder:\n","    def __init__(self,vocab_size,wordvec_size,hidden_size):\n","        V,D,H=vocab_size,wordvec_size,hidden_size\n","        rn=np.random.randn\n","\n","        #重みの初期化\n","        embed_W=(rn(V,D)/100).astype('f')\n","        lstm_Wx=(rn(D,4*H)/np.sqrt(D)).astype('f')\n","        lstm_Wh=(rn(H,4*H)/np.sqrt(H)).astype('f')\n","        lstm_b=np.zeros(4*H).astype('f')\n","        affine_W=(rn(H,V)/np.sqrt(H)).astype('f')\n","        affine_b=np.zeros(V).astype('f')\n","\n","        #レイヤの生成\n","        self.embed=TimeEmbedding(embed_W)\n","        self.lstm=TimeLSTM(lstm_Wx,lstm_Wh,lstm_b,stateful=True)    #エンコーダから受け取った隠れ状態を維持する\n","        self.affine=TimeAffine(affine_W,affine_b)\n","\n","        #パラメータの格納\n","        self.params,self.grads=[],[]\n","        self.params=self.embed.params+self.lstm.params+self.affine.params\n","        self.grads=self.embed.grads+self.lstm.grads+self.affine.grads\n","\n","    def forward(self,xs,h):\n","        self.lstm.set_state(h)\n","        out=self.embed.forward(xs)\n","        out=self.lstm.forward(out)\n","        score=self.affine.forward(out)\n","        return score\n","\n","    def backward(self,dscore):\n","        dout=self.affine.backward(dscore)\n","        dout=self.lstm.backward(dout)\n","        dout=self.embed.backward(dout)\n","        dh=self.lstm.dh\n","        return dh\n","\n","    def generate(self,h,start_id,sample_size):\n","        sampled=[]\n","        sample_id=start_id\n","        self.lstm.set_state(h)\n","\n","        for _ in range(sample_size):\n","            x=np.array(sample_id).reshape((1,1))  #sampledを二次元の配列に変換してxに格納\n","            out=self.embed.forward(x)\n","            out=self.lstm.forward(out)\n","            score=self.affine.forward(out)\n","\n","            sample_id=np.argmax(score.flatten())   #scoreを１次元のベクトルに変換して最大値のインデックスを取得\n","            sampled.append(int(sample_id))\n","\n","        return sampled"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lBLOFTt4_M1y"},"source":["class Seq2seq(BaseModel):\n","    def __init__(self,vocab_size,wordvec_size,hidden_size):\n","        V,D,H=vocab_size,wordvec_size,hidden_size\n","\n","        self.encoder=Encoder(V,D,H)\n","        self.decoder=Decoder(V,D,H)\n","        self.softmax=TimeSoftmaxWithLoss()\n","\n","        self.params=self.encoder.params+self.decoder.params\n","        self.grads=self.encoder.grads+self.decoder.grads\n","\n","    def forward(self,xs,ts):\n","        decoder_xs,decoder_ts=ts[:,:-1],ts[:,1:]    #tsが['_','6','2',' ',' ']のときdecoder_xsは['_','6','2',' ']、decoder_tsは['6','2',' ',' ']\n","        h=self.encoder.forward(xs)\n","        score=self.decoder.forward(decoder_xs,h)\n","        loss=self.softmax.forward(score,decoder_ts)\n","        return loss\n","\n","    def backward(self,dout=1):\n","        dout=self.softmax.backward(dout)\n","        dh=self.decoder.backward(dout)\n","        dout=self.encoder.backward(dh)\n","        return dout\n","\n","    def generate(self,xs,start_id,sample_size):\n","        h=self.encoder.forward(xs)\n","        sampled=self.decoder.generate(h,start_id,sample_size)\n","        return sampled"],"execution_count":null,"outputs":[]}]}