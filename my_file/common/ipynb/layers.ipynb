{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"layers.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNf9Qu4Aq9GE0SdXD0xIVPy"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"KNJplVeJ-Z2j"},"source":["from common.np import *  # import numpy as np\n","from common.config import GPU\n","from common.functions import *"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uZcSCHYEH4JC"},"source":["class MatMul:\n","    def __init__(self,W):\n","        self.params=[W]\n","        self.grads=[np.zeros_like(W)]\n","        self.x=None\n","\n","    def forward(self,x):\n","        W,=self.params\n","        out=np.dot(x,W)\n","        self.x=x\n","        return out\n","\n","    def backward(self,dout):\n","        W,=self.params\n","        dx=np.dot(dout,W.T)\n","        dW=np.dot(self.x.T,dout)\n","        self.grads[0][...]=dW\n","        return dx"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QhXc_kJHbdJl"},"source":["class Sigmoid:\n","    def __init__(self):\n","        self.params=[]\n","        self.grads=[]\n","        self.out=None\n","\n","    def forward(self,x):\n","        out=1/(1+np.exp(-x))\n","        self.out=out\n","        return out\n","\n","    def backward(self,dout):\n","        dx=self.out*(1.-self.out)*dout\n","        return dx\n","\n","class Affine:\n","    def __init__(self,W,b):\n","        self.params=[W,b]\n","        self.grads=[np.zeros_like(W),np.zeros_like(b)]\n","        self.x=None\n","\n","    def forward(self,x):\n","        W,b=self.params\n","        out=np.dot(x,W)+b\n","        self.x=x\n","        return out\n","\n","    def backward(self,dout):\n","        W,b=self.params\n","        db=np.sum(dout,axis=0)\n","        dx=np.dot(dout,W.T)\n","        dW=np.dot(self.x.T,dout)\n","        self.grads[0][...]=dW\n","        self.grads[1][...]=db\n","        return dx"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qfzjt8IdxW7h"},"source":["class SoftmaxWithLoss:\n","    def __init__(self):\n","        self.params=[]\n","        self.grads=[]\n","        self.y=None\n","        self.t=None\n","\n","    def forward(self,x,t):\n","        self.y=softmax(x)\n","        self.t=t\n","        if self.t.size==self.y.size:    #tがone-hot-vectorの場合ラベル表記に変換する\n","            self.t=np.argmax(self.t,axis=1)\n","        # if self.t.ndim!=1:\n","            # self.t=np.argmax(self.t,axis=1)\n","        loss=cross_entropy_error(self.y,self.t)\n","        return loss\n","\n","    def backward(self,dout=1):\n","        #backward時のself.tはforward時にラベル表記に変換されている\n","        batch_size=self.t.shape[0]\n","        dx=self.y.copy()\n","        dx[np.arange(batch_size),self.t]-=1 #one_hot_vectorの１を引く\n","        dx*=dout\n","        dx=dx/batch_size\n","        return dx"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qAOlwzPJ9L8p"},"source":["class SigmoidWithLoss:\n","    def __init__(self):\n","        self.params,self.grads=[],[]\n","        self.loss=None\n","        self.y=None\n","        self.t=None\n","\n","    def forward(self,x,t):\n","        self.y=1/(1+np.exp(-x))\n","        self.t=t\n","\n","        #t=0(負例)の場合はnp.c_[1-self.y,self.y][0]、すなわち1-self.yの確率を使用して交差エントロピー誤差を計算する\n","        #t=0 or 1のため、tの値がそのままnp.c_[1-self.y,self.y]のインデックスになる\n","        self.loss=cross_entropy_error(np.c_[1-self.y,self.y],self.t)\n","        return self.loss\n","\n","    def backward(self,dout=1):\n","        batch_size=self.t.shape[0]\n","        dx=(self.y-self.t)/batch_size*dout\n","\n","        return dx"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0iXp-9RTlYtF"},"source":["class Embedding:\n","    def __init__(self,W):\n","        self.params=[W]\n","        self.grads=[np.zeros_like(W)]\n","        self.idx=None\n","\n","    def forward(self,idx):\n","        W,=self.params\n","        self.idx=idx\n","        out=W[idx]\n","        return out\n","\n","    def backward(self,dout):\n","        dW,=self.grads\n","        dW[...]=0\n","        if GPU:\n","            np.scatter_add(dW, self.idx, dout)\n","        else:\n","            # dW[self.idx]=dout #←重複したidxに対応できない誤った実装\n","            # for i,word_id in enumerate(self.idx): #正しいが処理が遅い実装\n","            #     dout[word_id]+=dout[i]\n","\n","            #重複したidxの要素は加算する\n","            np.add.at(dW, self.idx, dout)\n","        return None"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"agANL502MnMe"},"source":["class Softmax:\n","    def __init__(self):\n","        self.params,self.grads=[],[]\n","        self.out=None\n","\n","    def forward(self,x):\n","        self.out=softmax(x)\n","        return self.out\n","\n","    def backward(self,dout):\n","        dx=dout*self.out\n","        sumdx=np.sum(dx,axis=1,keepdims=True)\n","        dx -= self.out * sumdx\n","        return dx"],"execution_count":null,"outputs":[]}]}