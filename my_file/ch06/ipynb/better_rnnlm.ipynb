{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"better_rnnlm.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNzdH/rmR9Op739ESG1JsjB"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"6fmNq7D3igg4"},"source":["import sys\n","sys.path.append('..')\n","from common.time_layers import *\n","from common.np import *  # import numpy as np\n","from common.base_model import BaseModel"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ByfrRDCaie9f"},"source":["class BetterRnnlm(BaseModel):\n","    def __init__(self,vocab_size=10000,wordvec_size=650,hidden_size=650,dropout_ratio=0.5):\n","        #重みの初期化\n","        V,D,H=vocab_size,wordvec_size,hidden_size\n","        rn=np.random.randn\n","\n","        embed_W=(rn(V,D)/100).astype('f')\n","        lstm1_Wx=(rn(D,4*H)/np.sqrt(D)).astype('f')\n","        lstm1_Wh=(rn(H,4*H)/np.sqrt(H)).astype('f')\n","        lstm1_b=np.zeros(4*H).astype('f')\n","        lstm2_Wx=(rn(H,4*H)/np.sqrt(D)).astype('f') #２つ目のLSTMレイヤへの入力は、１つ目のLSTMレイヤの出力hs(N,T,H)のため、重みWxの形状は(H,4*H)\n","        lstm2_Wh=(rn(H,4*H)/np.sqrt(H)).astype('f')\n","        lstm2_b=np.zeros(4*H).astype('f')\n","        affine_b=np.zeros(V).astype('f')\n","\n","        #レイヤの生成\n","        self.layers=[\n","                     TimeEmbedding(embed_W),\n","                     TimeDropout(dropout_ratio),\n","                     TimeLSTM(lstm1_Wx,lstm1_Wh,lstm1_b,stateful=True),\n","                     TimeDropout(dropout_ratio),\n","                     TimeLSTM(lstm2_Wx,lstm2_Wh,lstm2_b,stateful=True),\n","                     TimeDropout(dropout_ratio),\n","                     TimeAffine(embed_W.T,affine_b)   #Embeddingレイヤと重みを共有\n","        ]\n","        self.loss_layer=TimeSoftmaxWithLoss()\n","        self.lstm_layers=[self.layers[2],self.layers[4]]\n","        self.drop_layers=[self.layers[1],self.layers[3],self.layers[5]]\n","\n","        #パラメータの格納\n","        self.params,self.grads=[],[]\n","        for layer in self.layers:\n","            self.params+=layer.params\n","            self.grads+=layer.grads\n","\n","    def predict(self,xs,train_flg=False):\n","        for layer in self.drop_layers:\n","            layer.train_flg=train_flg\n","        for layer in self.layers:\n","            xs=layer.forward(xs)\n","        return xs\n","\n","    def forward(self,xs,ts,train_flg=True):\n","        score=self.predict(xs,train_flg)\n","        loss=self.loss_layer.forward(score,ts)\n","        return loss\n","\n","    def backward(self,dout=1):\n","        dout=self.loss_layer.backward(dout)\n","        for layer in reversed(self.layers):\n","            dout=layer.backward(dout)\n","        return dout\n","\n","    def reset_state(self):\n","        for layer in self.lstm_layers:\n","            layer.reset_state()"],"execution_count":null,"outputs":[]}]}